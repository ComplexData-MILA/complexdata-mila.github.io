---
title: 'Unveiling Identity Biases in Toxicity Detection : A Game-Focused Dataset and
  Reactivity Analysis Approach'
venue: Conference on Empirical Methods in Natural Language Processing
names: J. Dorpe, Zachary Yang, Nicolas Grenon-Godbout, Grégoire Winterstein
tags:
- Conference on Empirical Methods in Natural Language Processing
link: https://doi.org/10.18653/v1/2023.emnlp-industry.26
code: https://github.com/ubisoft/Ubisoft-LaForge-ToxPlainerDataSet
author: Zachary Yang
categories: 
- Publications
- online-toxicity
excerpt: "Identity biases arise commonly from annotated datasets, can be propagated in language models and can cause further harm to marginal groups. Existing bias benchmarking datasets are mainly focused on gender or racial biases and are made to pinpoint which class the model is biased towards. They also are not designed for the gaming industry, a concern for models built for toxicity detection in videogames’ chat."

---

*{{ page.names }}*

**{{ page.venue }}**

{% include display-publication-links.html pub=page %}

## Abstract

,