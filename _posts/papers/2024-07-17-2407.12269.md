---
title: 'UTG: Towards a Unified View of Snapshot and Event Based Models for Temporal
  Graphs'
venue: Learning on Graph Conference
names: Shenyang Huang, Farimah Poursafaei, Reihaneh Rabbany, Guillaume Rabusseau,
  Emanuele Rossi
tags:
- Learning on Graph Conference
link: https://openreview.net/pdf?id=ZKHV6Cpsxg
code: https://github.com/shenyangHuang/UTG
author: Shenyang Huang
categories: 
- Publications
- TGB
excerpt: Here we introduce the Unified Temporal Graph (UTG) framework, which integrates snapshot-based and event-based machine learning models for temporal graphs under a single framework. This unification allows models developed for one type of temporal graph representation to be effectively applied to the other, addressing the previous isolation in their development. The research comprehensively evaluates both snapshot and event-based models on temporal link prediction tasks, revealing that snapshot-based models, when combined with UTG training, can perform competitively with event-based models like TGN and GraphMixer, even on event datasets. This work promotes experimental comparison and theoretical cross-pollination between the two approaches, advancing the field of temporal graph learning


---

*{{ page.names }}*

**{{ page.venue }}**

{% include display-publication-links.html pub=page %}

## Abstract

Many real world graphs are inherently dynamic, constantly evolving with node and edge additions. These graphs can be represented by temporal graphs, either through a stream of edge events or a sequence of graph snapshots. Until now, the development of machine learning methods for both types has occurred largely in isolation, resulting in limited experimental comparison and theoretical crosspollination between the two. In this paper, we introduce Unified Temporal Graph (UTG), a framework that unifies snapshot-based and event-based machine learning models under a single umbrella, enabling models developed for one representation to be applied effectively to datasets of the other. We also propose a novel UTG training procedure to boost the performance of snapshot-based models in the streaming setting. We comprehensively evaluate both snapshot and event-based models across both types of temporal graphs on the temporal link prediction task. Our main findings are threefold: first, when combined with UTG training, snapshot-based models can perform competitively with event-based models such as TGN and GraphMixer even on event datasets. Second, snapshot-based models are at least an order of magnitude faster than most event-based models during inference. Third, while event-based methods such as NAT and DyGFormer outperforms snapshot-based methods on both types of temporal graphs, this is because they leverage joint neighborhood structural features thus emphasizing the potential to incorporate these features into snapshotbased models as well. These findings highlight the importance of comparing model architectures independent of the data format and suggest the potential of combining the efficiency of snapshot-based models with the performance of event-based models in the future.